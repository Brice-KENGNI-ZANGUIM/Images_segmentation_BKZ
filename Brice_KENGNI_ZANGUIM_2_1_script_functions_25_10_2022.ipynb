{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10a91a80-881d-4b0b-85de-0e3856b7768f",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################\n",
    "########################################################################################\n",
    "\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "########################################################################################\n",
    "########################################################################################\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import keras\n",
    "import os\n",
    "from PIL import Image\n",
    "import PIL\n",
    "import cv2\n",
    "import wordcloud\n",
    "from matplotlib import colors\n",
    "\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import shutil\n",
    "from glob import glob\n",
    "\n",
    "########################################################################################\n",
    "##########################       Augmentation d'image       ############################\n",
    "\n",
    "try :\n",
    "    import imgaug    #  import imaug as ia\n",
    "    import imgaug as ia\n",
    "except :\n",
    "    !pip install imgaug\n",
    "    import imgaug     #  import imaug as ia\n",
    "    import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "from imgaug.augmentables.segmaps import SegmentationMapsOnImage\n",
    "from imgaug.augmentables.batches import UnnormalizedBatch\n",
    "\n",
    "########################################################################################\n",
    "########################################################################################\n",
    "from sklearn.base import BaseEstimator,TransformerMixin\n",
    "\n",
    "########################################################################################\n",
    "########################################################################################\n",
    "\n",
    "try :\n",
    "    from tensorflow.keras.preprocessing.image import image_utils\n",
    "except :\n",
    "    from tensorflow.keras.preprocessing import image as image_utils\n",
    "    \n",
    "from tensorflow.python.keras.losses import CategoricalCrossentropy, BinaryCrossentropy, categorical_crossentropy\n",
    "from tensorflow.python.keras import backend as K\n",
    "import tensorflow.compat.v2 as tf\n",
    "\n",
    "########################################################################################\n",
    "########################################################################################\n",
    "\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer , CountVectorizer\n",
    "from sklearn import preprocessing, manifold, metrics\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from tensorflow.python.keras.losses import binary_crossentropy, categorical_crossentropy\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "########################################################################################\n",
    "########################################################################################\n",
    "\n",
    "import seaborn as sns\n",
    "#%matplotlib inline\n",
    "#%matplotlib notebook\n",
    "sns.set()\n",
    "\n",
    "########################################################################################\n",
    "########################################################################################\n",
    "\n",
    "#!pip3 install --upgrade tensorflow-gpu\n",
    "# Install TF-Hub.\n",
    "#!pip3 install tensorflow-hub\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fd0695d-af18-4f5f-8c5d-69af1d7c1035",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(Y_true , Y_predict, title=\"Matrice de confusion\", cmap=\"hot_r\", figsize = (12,8), tic_rot= (0,0)):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "        warnings.filterwarnings('ignore')\n",
    "        Y_true , Y_predict = np.asarray(Y_true), np.asarray(Y_predict)\n",
    "        df_confusion = pd.crosstab(Y_true, Y_predict, rownames=['True Labels\\n'], colnames=['\\nPredicted Labels'])\n",
    "        plt.figure(figsize=figsize)\n",
    "        sns.heatmap(df_confusion, cmap=cmap, annot =True) # imshow\n",
    "        plt.title(title,size =3*figsize[0])\n",
    "        #plt.colorbar()\n",
    "        tick_marks = np.arange(len(df_confusion.columns)) +0.5\n",
    "        plt.xticks(tick_marks, df_confusion.columns, rotation=tic_rot[0], size=1.5*figsize[0])\n",
    "        plt.yticks(tick_marks, df_confusion.index, rotation=tic_rot[1], size = 1.5*figsize[0])\n",
    "        #plt.tight_layout()\n",
    "        plt.ylabel(df_confusion.index.name, size = 2*figsize[0] )\n",
    "        plt.xlabel(df_confusion.columns.name, size = 2*figsize[0])\n",
    "        plt.show()\n",
    "\n",
    "def get_train_test_index( datas , label = \"label\", nombre=[200,200,200] ) :\n",
    "    data = datas.copy()\n",
    "    shape_0 = int(data.shape[0]/data[label].nunique())\n",
    "    # si les valeurs sont inférieures à zéro\n",
    "    if nombre[0]<1 and nombre[1]<1 and nombre[2]<1 :\n",
    "            nombre[0] = int( nombre[0]*shape_0 )\n",
    "            nombre[1] = int( nombre[1]*shape_0 )\n",
    "            nombre[2] = int( nombre[2]*shape_0 )\n",
    "    \n",
    "    # Si la somme des valeurs est différente de la taille des données\n",
    "    if np.sum(nombre) != shape_0 :\n",
    "        nombre[1] = (shape_0 - nombre[0])//2\n",
    "        nombre[2] = nombre[1]\n",
    "        nombre[0] = shape_0 - 2*nombre[1]\n",
    "        \n",
    "    #for i in range(3) : print(nombre[i])\n",
    "    #print(np.sum(nombre)*data[label].nunique())\n",
    "    \n",
    "    idx = [[] for i in range(len(nombre)) ]\n",
    "    for i in range(len(nombre)) :\n",
    "        if i != len(nombre) -1 :\n",
    "            for cat in data[label].unique() : \n",
    "                sub_data = data[ data[label] == cat]\n",
    "                for j in random.sample( sorted(sub_data.index.values), nombre[i] ) :\n",
    "                    idx[i].append(j)\n",
    "            data.drop(index=idx[i] , inplace=True)\n",
    "            idx[i] = sorted(idx[i])\n",
    "        else :\n",
    "            idx[i] = data.index\n",
    "            idx[i] = sorted(idx[i])\n",
    "    \n",
    "    return idx\n",
    "\n",
    "def prediction_function_threshold ( model=None , X=None, Y_proba=None , seuil = 0.5 ) :\n",
    "    \"\"\"\n",
    "    La fonction permet d'évaluer la prediction d'un modèle donnée en fonction du modèle, de l'entrée, d'une probabilité fournie et d'un seuil \n",
    "    \n",
    "    Paramètres :\n",
    "    ------------\n",
    "        model : modèle de machine learning à utiliser.\n",
    "        X : pandas.core.frame.DataFrame\n",
    "            donnée à fournir au modèle pour la prédiction. Si model est fourni alors X doit aussi être fourni et dans ce cas Y_proba n'est pas utilisé.\n",
    "        Y_proba : Array_type\n",
    "            probabilité qu'un individu soit du label positif. Si Y_proba est fourni alors model et X ne sont pas utilisés\n",
    "        seuil : float\n",
    "            seuil de probalité à utiliser pour la calcul de la prediction. la valeur par defaus est 0.5 et doit toujours être comprise entre 0 et 1\n",
    "    \n",
    "    Return : Array_type\n",
    "        prediction\n",
    "        \n",
    "    \"\"\"\n",
    "    if ( type(model) == type(None) ) and ( type(X) == type(None) ): \n",
    "        return np.array( Y_proba > seuil , dtype = int)\n",
    "    else :\n",
    "        try : \n",
    "            return np.array( model.predict_proba(X)[:,1] > seuil , dtype = int)\n",
    "        except :\n",
    "            print(\"Le modèle que vous avez fourni ne possède pas de méthode 'predict_proba()'\")\n",
    "            return\n",
    "        \n",
    "#  Definition de la meilleure métrique \n",
    "#  Definition de la meilleure métrique \n",
    "def my_cost( y , y_pred , poids = 4  , seuil = np.linspace(0.008,0.999,50 ) , scorer = False ) : \n",
    "    \"\"\"\n",
    "    La fonction permet d'évaluer le cout métier d'un modèle donné, elle évalue le cout métier pour chaque valeurs du seuil\n",
    "    de probabilité\n",
    "    \n",
    "    Paramètres :\n",
    "    ------------\n",
    "        y : Array_like \n",
    "            vraie valeur labels pour chaque individus ou observations\n",
    "        y_pred : Array_like \n",
    "            vecteur probabilité ( d'être positif  ) peu aussi être le vecteur prediction du modèle pour chaque individus ou observations\n",
    "            \n",
    "    return : dict\n",
    "    ------------\n",
    "        out : dict \n",
    "        La dictionnaire renvoyé est de la forme : \n",
    "        { \"cout\" : Array_type de variation du coût en fonction du seuil , \"cout_min\" : valeur du coût minimal , \"seuil_min\" : seuil correspondant au cout minimal }\n",
    "    \n",
    "    Author : \n",
    "    -----------\n",
    "        Name : Brice KENGNI ZANGUIM\n",
    "        e-mail : kenzabri2@yahoo.com\n",
    "    \n",
    "    \"\"\"\n",
    "    if type(y) == type(pd.DataFrame()) :\n",
    "        label = pd.DataFrame( {\"Y_test\" : y.values.reshape( (y.shape[0],) ) , \"Y_prob\" : y_pred } )\n",
    "    else :\n",
    "        label = pd.DataFrame( {\"Y_test\" : y , \"Y_prob\" : y_pred } )\n",
    "\n",
    "    out = {\"cout\" : []}\n",
    "    if type(seuil) in [ float , np.float16, np.float32, np.float64] : \n",
    "        label[\"Y_pred\"] = label[\"Y_prob\"].apply( lambda x : int(x > seuil))\n",
    "        label.loc[ (label[\"Y_test\"] ==0) & (label[\"Y_pred\"] == 0) , \"decision\"]  = \"VN\"\n",
    "        label.loc[ (label[\"Y_test\"] ==1) & (label[\"Y_pred\"] == 1) , \"decision\"]  = \"VP\"\n",
    "        label.loc[ (label[\"Y_test\"] ==0) & (label[\"Y_pred\"] == 1) , \"decision\"]  = \"FP\"\n",
    "        label.loc[ (label[\"Y_test\"] ==1) & (label[\"Y_pred\"] == 0) , \"decision\"]  = \"FN\"\n",
    "        return ( label[\"decision\"] == \"FP\" ).mean() + poids*( label[\"decision\"] == \"FN\" ).mean()\n",
    "    else :\n",
    "        for s in seuil : \n",
    "            label[\"Y_pred\"] = label[\"Y_prob\"].apply( lambda x : int(x > s))\n",
    "            label.loc[ (label[\"Y_test\"] ==0) & (label[\"Y_pred\"] == 0) , \"decision\"]  = \"VN\"\n",
    "            label.loc[ (label[\"Y_test\"] ==1) & (label[\"Y_pred\"] == 1) , \"decision\"]  = \"VP\"\n",
    "            label.loc[ (label[\"Y_test\"] ==0) & (label[\"Y_pred\"] == 1) , \"decision\"]  = \"FP\"\n",
    "            label.loc[ (label[\"Y_test\"] ==1) & (label[\"Y_pred\"] == 0) , \"decision\"]  = \"FN\"\n",
    "            \n",
    "            # Calcul du coût métier\n",
    "            out[\"cout\"].append( ( label[\"decision\"] == \"FP\" ).mean() + poids*( label[\"decision\"] == \"FN\" ).mean() )\n",
    "\n",
    "        out[\"cout\"] = np.array(out[\"cout\"])\n",
    "        # Si le cout métier est utilisé comme scorer ou métrique  alors la fonction retourne la valeur minimale pour \n",
    "        # toutes les valeurs de seuil probabilité renseignées\n",
    "        if scorer : \n",
    "            return out[\"cout\"].min()\n",
    "        # Sinon la fonction revoie toutes les valeurs du cout métiers pour chaque valeurs du seuil de probabilité\n",
    "        else : \n",
    "            out[\"cout_min\"] = out[\"cout\"].min()\n",
    "            out[\"seuil_min\"] = seuil[out[\"cout\"] == out[\"cout_min\"]]\n",
    "            out[\"cout\"] = list(out[\"cout\"])\n",
    "            return out\n",
    "        \n",
    "def print_scores(model = None , X_test=None , Y_true=None , Y_proba = None  , line_width = 6 , seuil = np.linspace( 0 , 0.9 , 90 ) ,\n",
    "                 plot_kind = \"apr\", give_results = False , show_graph = True, poids = None, fig_sz = (12,8)) :\n",
    "    scores = {} \n",
    "    beta = np.linspace( 0.7 , 2. , 2 )\n",
    "    if ( type(model)!=type(None) ) and ( type(X_test)!=type(None) ) and ( type(Y_proba) == type(None) ) :\n",
    "        try :\n",
    "            Y_proba = model.predict_proba(X_test)[:,1]\n",
    "        except :\n",
    "            print(\"Le modèle que vous avez fourni ne possède pas de méthode 'predict_proba'\")\n",
    "            return\n",
    "    \n",
    "    ## Pour chaque coefficient beta de F_beta score, je vais calculter la variation du F_beta score avec le seuil\n",
    "    if \"b\" in plot_kind :\n",
    "        for b in beta :\n",
    "            scores[f\"beta = {b}\"] = [  metrics.fbeta_score(Y_true , prediction_function_threshold(Y_proba = Y_proba ,seuil = s) , beta = b ) for s in seuil ]\n",
    "    if \"a\" in plot_kind :\n",
    "        scores[f\"Accuracy\"] = [ metrics.accuracy_score(Y_true , prediction_function_threshold(Y_proba = Y_proba ,seuil = s)  )  for s in seuil  ]      #  Accuracy en fonction du seuil\n",
    "    if \"r\" in plot_kind :\n",
    "        scores[f\"Recall\"] = [ metrics.recall_score(Y_true , prediction_function_threshold(Y_proba = Y_proba ,seuil = s)  ) for s in seuil  ]           #  Recall en fonction du seuil\n",
    "    if \"p\" in plot_kind :\n",
    "        scores[f\"Precision\"] = [ metrics.precision_score(Y_true , prediction_function_threshold(Y_proba = Y_proba ,seuil = s)  ) for s in seuil  ]     #  Precision en fonction du seuil\n",
    "    if \"h\" in plot_kind :\n",
    "        scores[f\"Hamming Loss\"] = [ metrics.hamming_loss(Y_true , prediction_function_threshold(Y_proba = Y_proba ,seuil = s)  ) for s in seuil  ]     #  Precision en fonction du seuil\n",
    "    if \"c\" in plot_kind :\n",
    "        scores[\"Fonction Coût\"] = my_cost(Y_true , Y_proba , seuil = seuil ,scorer=False, poids = poids)[\"cout\"]     #  Precision en fonction du seuil\n",
    "    \n",
    "    if show_graph :\n",
    "        #  Affichage de la figure\n",
    "        plt.figure(figsize = fig_sz)\n",
    "        plt.title(\"\\nF_beta-accuracy-Précision-Recall VS seuil\" , size=2*fig_sz[0])\n",
    "        plt.xlabel(\" Seuil de probabilité\" , size= 1.5*fig_sz[0])\n",
    "        plt.ylabel(\"SCORE\" , size = 1.5*fig_sz[0] )\n",
    "        \n",
    "        for label , y  in scores.items()  :\n",
    "            plt.plot(seuil , y , lw = line_width ,ls = np.random.choice([\"dashed\",\"dotted\", \"dashdot\", \"solid\"]), label = f\"{label}\")\n",
    "            \n",
    "        plt.legend(loc=\"best\" , fontsize=\"xx-large\")\n",
    "        plt.show()\n",
    "        scores[\"seuil\"] = seuil\n",
    "    if give_results : return pd.DataFrame(scores ).set_index(\"seuil\")\n",
    "\n",
    "def world_and_number_cloud_show( data, fig_size = (8,5), max_wd = 150, do_mask = False, horizontal= .85, save_name = \"worcloud.png\", \n",
    "                     min_font = 5, font_step= 2, save_fig = True,indice= \"_\") :\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "        #####################  Si toutes les données sont des valeurs numériques\n",
    "        if np.all( [ not isinstance(data[i], str)  for i in range(len(data))] )  :\n",
    "            f = np.vectorize(lambda x : f\"{indice}{x}\")\n",
    "            data = list(f(data).ravel())\n",
    "        \n",
    "        if do_mask : \n",
    "            mask = np.array(Image.open(\"cloud.jpg\"))\n",
    "            mask[mask > 1] = 255\n",
    "            x = wordcloud.WordCloud(width = fig_size[0]*100, height = fig_size[1]*100, background_color ='white', colormap=\"plasma\", max_words=max_wd,\n",
    "                                    repeat = False, min_font_size=min_font, font_step=font_step, prefer_horizontal = horizontal, mask = mask,\n",
    "                                    relative_scaling =0, collocations =False).generate(\" \".join( data))\n",
    "        else :\n",
    "            x = wordcloud.WordCloud(width = fig_size[0]*100, height = fig_size[1]*100, background_color ='white', colormap=\"plasma\", max_words=max_wd,\n",
    "                                    repeat = False, min_font_size=min_font, font_step=font_step, prefer_horizontal = horizontal,relative_scaling =0,\n",
    "                                    collocations =False).generate(\" \".join( data))\n",
    "\n",
    "        # plot the WordCloud image                      \n",
    "        plt.figure(figsize = fig_size, facecolor = None)\n",
    "        plt.imshow(x)\n",
    "        plt.axis(\"off\")\n",
    "        plt.tight_layout(pad = 0)\n",
    "        if save_fig : plt.savefig(save_name)\n",
    "        plt.show()\n",
    "        \n",
    "def process_images ( data , label=\"images\" , process_type = \"MEC\", resolution =( 128,128),filter_size = 3): \n",
    "    if type(data) == type(pd.DataFrame()) :\n",
    "        data = data.copy()\n",
    "\n",
    "        if \"E\" in process_type :\n",
    "            # Uniformisation de la distributuion de pixels\n",
    "            data[\"images_processes\"] = data[label].apply(lambda image : PIL.ImageOps.equalize(image ) ) \n",
    "\n",
    "        if \"G\" in process_type :\n",
    "            #picts[\"images_process\"] = picts.images_process.apply(lambda image : img_repixels( image,  20, 220) )\n",
    "            data[\"images_processes\"] = data.images_processes.apply(lambda image : image.filter( PIL.ImageFilter.GaussianBlur(gauss_size) )  )\n",
    "        if \"C\" in process_type :\n",
    "            # Mise en contraste de l'image\n",
    "            data[\"images_processes\"] = data.images_processes.apply(lambda image : PIL.ImageOps.autocontrast( image )  )\n",
    "        \n",
    "        if \"R\" in process_type :\n",
    "            data[\"images_processes\"] = data.images_processes.apply( lambda img : np.asarray(img) )\n",
    "            data['images_processes'] = data.images_processes.apply( lambda img :  img.resize( resolution, resample = PIL.Image.Resampling.BICUBIC) )\n",
    "\n",
    "        data['images_process'] = data[\"images_processes\"]\n",
    "        data.drop( columns=[\"images_processes\"] ,inplace = True)\n",
    "        return data\n",
    "    else :\n",
    "        image = data\n",
    "        from PIL import ImageOps\n",
    "        if \"C\" in process_type :\n",
    "            # Mise en contraste de l'image\n",
    "            image = ImageOps.autocontrast( image )\n",
    "        if \"E\" in process_type :\n",
    "            # Uniformisation de la distributuion de pixels\n",
    "            image =  PIL.ImageOps.equalize( image )\n",
    "        if \"M\" in process_type :\n",
    "            if filter_size%2 == 0 : filter_size += 1\n",
    "            # application d'un median\n",
    "            image =  image.filter( PIL.ImageFilter.MedianFilter(filter_size) )\n",
    "        elif \"G\" in process_type :\n",
    "            # Application du filtre gaussien\n",
    "            # picts[\"images_process\"] = picts.images_process.apply(lambda image : img_repixels( image,  20, 220) )\n",
    "            image = image.filter( PIL.ImageFilter.GaussianBlur(filter_size) )\n",
    "        if \"R\" in process_type :\n",
    "            #image = np.asarray(image) \n",
    "            image = image.resize( resolution, resample = PIL.Image.Resampling.LANCZOS )\n",
    "            #image = PIL.Image.fr(image)\n",
    "        return image\n",
    "\n",
    "\n",
    "def afficher_une_serie_d_images( true_img, predict_img_0, predict_img_1 = None,\n",
    "                                n = 1, figsize = (16,8), gray = False, title = [\" \",\" \",\" \"], alpha = 1 , external_style = False) :\n",
    "    \n",
    "    if isinstance( true_img, list ) :\n",
    "        true_img = np.array([ true_img[i] for i in  range(len(true_img))] )\n",
    "        predict_img_0 = np.array( [ predict_img_0[i] for i in range(len(predict_img_0))] )\n",
    "        if not isinstance( predict_img_1, type(None) ) :\n",
    "            predict_img_1 = np.array( [ predict_img_1[i] for i in range(len(predict_img_1))] )\n",
    "    if isinstance( true_img[0], str ) :\n",
    "        true_img = [ image_utils.load_img( true_img[i], grayscale=gray)  for i in range(len(true_img)) ] \n",
    "        predict_img_0 = [  image_utils.load_img(predict_img_0[i], grayscale=gray) for i in range(len(true_img)) ] \n",
    "        if not isinstance( predict_img_1, type(None) ) :\n",
    "            predict_img_1 = [  image_utils.load_img(predict_img_1[i], grayscale=gray) for i in range(len(true_img))  ] \n",
    "\n",
    "    if  isinstance( predict_img_1, type(None) ) : \n",
    "        X = [ true_img, predict_img_0 ] \n",
    "    else  :\n",
    "        X = [ true_img, predict_img_0, predict_img_1 ] \n",
    "    ###########   Vérifier que le nombre de donées à afficher est inférieur au nombre de données disponibles ############\n",
    "    assert  n <= np.array(X[0]).shape[0] \n",
    "    \n",
    "    idx = np.sort( np.random.choice([i for i in range(np.array(X[0]).shape[0])], size=n , replace = False  ) )\n",
    "    \n",
    "    for ligne in range(n) :\n",
    "        \n",
    "        fig , ax = plt.subplots( 1,len(X), figsize = figsize, sharex=True )\n",
    "        for j in range(len(X)) :\n",
    "            if not external_style :\n",
    "                ax[j].imshow( X[ j ][ idx[ ligne ] ]) \n",
    "            elif external_style == 2 :\n",
    "                if j == 1  :\n",
    "                    ax[j].imshow( X[j-1][idx[ligne]] ) \n",
    "                    ax[j].imshow( X[j][idx[ligne]], alpha = alpha )\n",
    "\n",
    "                else :\n",
    "                    ax[j].imshow( X[j][idx[ligne]] ) \n",
    "            elif external_style == 3 :\n",
    "                if j == 2 :\n",
    "                    ax[j].imshow( X[j-2][idx[ligne]] ) \n",
    "                    ax[j].imshow( X[j-1][idx[ligne]], alpha = alpha )\n",
    "\n",
    "                else :\n",
    "                    ax[j].imshow( X[j][idx[ligne]] ) \n",
    "            \n",
    "            ax[j].set_title( title[j], size = 1.1*figsize[0] )\n",
    "            ax[j].grid(False)\n",
    "            ax[j].axis(\"off\")\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def afficher_les_images_supperposees( img1, img2 = None, style = 1, figsize = (15,8), alpha = 0.4, title = None ):\n",
    "    if isinstance(img1,str): \n",
    "        img1 = image_utils.load_img(img1)\n",
    "        if img2 :\n",
    "            img2 = image_utils.load_img(img2)\n",
    "    else :\n",
    "        img1, img2 = np.asarray(img1), np.asarray(img2)\n",
    "    \n",
    "    if style == 1 :\n",
    "        plt.figure(figsize=(16,8))\n",
    "        plt.imshow(img1 )\n",
    "        if np.all(img2) :\n",
    "            plt.imshow(img2, alpha  = alpha )\n",
    "            plt.title(\"Image + masque\", size = 1.5*figsize[0])\n",
    "        else : \n",
    "            plt.title( title, size = 1.5*figsize[0])\n",
    "        plt.grid(False)\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "        \n",
    "    elif style == 2 :\n",
    "        if title  :\n",
    "            afficher_une_serie_d_images([img1],[img2],n = 1, alpha = alpha, title=title, external_style=style,figsize=figsize)\n",
    "        else : \n",
    "            afficher_une_serie_d_images([img1],[img2],n = 1, alpha = alpha, title=[\"simple image\", \"supperposition\"], external_style=style,\n",
    "                                        figsize=figsize)\n",
    "            \n",
    "    elif style == 3 :\n",
    "        if title :\n",
    "            afficher_une_serie_d_images([img1],[img2],[img2],n = 1, alpha = alpha, title=title, external_style=style,figsize=figsize)\n",
    "        else :\n",
    "            afficher_une_serie_d_images([img1],[img2],[img2],n = 1, alpha = alpha, title=[\"simple image\",\"masque\" ,\"supperposition\"],\n",
    "                                        external_style=style,figsize=figsize)\n",
    "    else :\n",
    "        print(\"Le style d'affichage que vous avez selectionné n'est pasdisponible, veillez le changer\")\n",
    "\n",
    "\n",
    "\n",
    "def couleurs_uniques(img, return_counts = False) :\n",
    "    if isinstance(img, str) :\n",
    "        img = image_utils.load_img(img)\n",
    "    img = np.asarray(img)\n",
    "    \n",
    "    if return_counts :\n",
    "        tmp, count = np.unique( img.reshape( -1 , img.shape[-1] ) , axis = 0 , return_counts = return_counts )\n",
    "        return [f\"({i[0]},{i[1]},{i[2]})\" for i in tmp ], count\n",
    "    else :\n",
    "        tmp = np.unique( img.reshape( -1 , img.shape[-1] ) , axis = 0 )\n",
    "        return [f\"({i[0]},{i[1]},{i[2]})\" for i in tmp ]\n",
    "    \n",
    "def afficher_les_metriques( result, figsize = (15,10) ) :\n",
    "    fig, ax = plt.subplots(2,2, figsize = figsize )\n",
    "\n",
    "    ax[0,0].plot(result.index , result[\"Tversky_coef\"])\n",
    "    ax[0,0].plot(result.index , result[\"val_Tversky_coef\"])\n",
    "    ax[0,0].set_title( \"Tversky_coef\", size = 16 )\n",
    "    ax[0,0].legend([\"train\",\"val\"], loc = 'best')\n",
    "    #ax[0,0].set_xlabel(\"Itération\")\n",
    "\n",
    "    ax[0,1].plot(result.index , result[\"dice_coeff\"])\n",
    "    ax[0,1].plot(result.index , result[\"val_dice_coeff\"])\n",
    "    ax[0,1].set_title( \"dice_coeff\", size = 16 )\n",
    "    ax[0,1].legend([\"train\",\"val\"], loc = 'best')\n",
    "\n",
    "    ax[1,0].plot(result.index , result[\"mean_IoU\"])\n",
    "    ax[1,0].plot(result.index , result[\"val_mean_IoU\"])\n",
    "    ax[1,0].set_title( \"mean_IoU\", size = 16 )\n",
    "    ax[1,0].legend([\"train\",\"val\"], loc = 'best')\n",
    "\n",
    "    ax[1,1].plot(result.index , result[\"ARI_score\"])\n",
    "    ax[1,1].plot(result.index , result[\"val_ARI_score\"])\n",
    "    ax[1,1].set_title( \"ARI_score\", size = 16 )\n",
    "    ax[1,1].legend([\"train\",\"val\"], loc = 'best')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "class MyCallback( tf.keras.callbacks.Callback ):\n",
    "    \n",
    "    def __init__(self, seuil = 0.95) :\n",
    "        self.seuil = seuil\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if logs['dice_coeff'] > self.seuil and 0.99 < logs['ARI_score']  < 1. :\n",
    "            print(f\"\\n\\n La métrique dice_coeff > {self.seuil*100}; en conséquence de quoi l'entrainement est arrêté ! !\\n\")\n",
    "            self.model.stop_training = True\n",
    "        elif logs['mean_IoU'] > self.seuil and 0.99 < logs['ARI_score']  < 1.:\n",
    "            print(f\"\\n\\n La métrique mean_IoU > {self.seuil*100}; en conséquence de quoi l'entrainement est arrêté ! !\\n\")\n",
    "            self.model.stop_training = True\n",
    "        elif logs['Tversky_coef'] > self.seuil and 0.99 < logs['ARI_score']  < 1.:\n",
    "            print(f\"\\n\\n La métrique Tversky_coef > {self.seuil*100}; en conséquence de quoi l'entrainement est arrêté ! !\\n\")\n",
    "            self.model.stop_training = True\n",
    "            \n",
    "def scheduler(epoch, learning_rate):\n",
    "    \n",
    "    if epoch %10 == 4 :\n",
    "        return learning_rate*1.05\n",
    "    else :\n",
    "        return learning_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42299964-b77e-48a2-9942-6b660efad4ce",
   "metadata": {},
   "source": [
    "## <strong> Métriques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c02fca11-e78f-47c0-8ef5-5438611c72ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################\n",
    "##################     Dice loss et Coefficient de Dice     #######################\n",
    "###################################################################################\n",
    "\n",
    "def dice_coeff(y_true, y_pred):\n",
    "    \n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    score = (2.*intersection + smooth)/(K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return score\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    \n",
    "    return 1.0 - dice_coeff(y_true, y_pred)\n",
    "\n",
    "def binary_dice_entropy(y_true, y_pred):\n",
    "    \n",
    "    return categorical_crossentropy(y_true, y_pred) + 3*dice_loss(y_true, y_pred)\n",
    "    #return CategoricalCrossentropy()(y_true, y_pred) + 3*dice_loss(y_true, y_pred)\n",
    "\n",
    "##############################################################################\n",
    "##################     Tversky loss  with beta = 0.5   #######################\n",
    "##############################################################################\n",
    "\n",
    "def Tversky_coef(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.math.sigmoid(y_pred)\n",
    "    numerator = 2*y_true * y_pred\n",
    "    denominator = y_true + y_pred \n",
    "\n",
    "    return tf.reduce_sum(numerator) / tf.reduce_sum(denominator)\n",
    "\n",
    "def Tversky_loss(y_true, y_pred):\n",
    "    return 1.0 - Tversky_coef(y_true, y_pred)\n",
    "\n",
    "##############################################################################\n",
    "##################       Intersection sur l'union      #######################\n",
    "##############################################################################\n",
    "\n",
    "def mean_IoU(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    \n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    \n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    score = (intersection + 1.) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1. )\n",
    "    return score\n",
    "\n",
    "def IOU_good (y_true, y_pred ) :\n",
    "    y_true = tf.cast(  y_true , tf.float32 )\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    \n",
    "    y_true_f = K.flatten( y_true )\n",
    "    y_pred_f = K.flatten( y_pred )\n",
    "    \n",
    "    i = tf.cast( y_true_f == y_pred_f, tf.float32 )\n",
    "    j = tf.cast( y_true_f != y_pred_f, tf.float32 )\n",
    "    \n",
    "    intersection = tf.reduce_sum( i )\n",
    "    union = 2*tf.reduce_sum( j ) + intersection\n",
    "\n",
    "    return intersection/union\n",
    "\n",
    "def IoU_loss ( y_true, y_pred) :\n",
    "    \n",
    "    return 1.0 - mean_IoU(y_true, y_pred)\n",
    "\n",
    "def Iou_binary_cross_entropy ( y_true, y_pred) :\n",
    "    \n",
    "    return categorical_crossentropy( y_true, y_pred ) + 3*IoU_loss( y_true, y_pred )\n",
    "    #return CategoricalCrossentropy()( y_true, y_pred ) + 3*IoU_loss( y_true, y_pred )\n",
    "\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "##################          Segmentation ARI           #######################\n",
    "##############################################################################\n",
    "\n",
    "def ARI_score ( y_true, y_pred ) :\n",
    "    \"\"\"\n",
    "    Implementation du score Adjusted Rand score des auteurs Lawrence Hubert  et Phipps Arabic publié dans Journal of Classification en 1985 \n",
    "    - https://en.wikipedia.org/wiki/Rand_index \n",
    "    - Equation 5 de l'article : https://pdfslide.net/documents/lawrence-hubert-and-phipps-arabie-comparing-partitions-1985.html?page=1\n",
    "    \n",
    "    Le score permet de mesurer la similitude entre deux partition d'un memê ensemble. ici je l'adpate pour l'évaluation des performances \n",
    "    d'une segmentation d'images. la même métrique est disponible sous scikit learn \n",
    "    ( https://scikit-learn.org/stable/modules/generated/sklearn.metrics.adjusted_rand_score.html) mais s'avère impuissante pour des entrées \n",
    "    `y_true` et `y_pred` de type Tensorielle comme celles qui peuvent être fournies par la sortie d'un réseau de convolution.\n",
    "    \n",
    "    Liberté vous est donnée de de copier, partager, modifier, améliorer le code à votre gré.\n",
    "    Paramètres :\n",
    "    ------------\n",
    "        y_true, y_pred : Tensor de la forme ( hauteur, largeur , canal ): \n",
    "      Auteur :\n",
    "    -----------\n",
    "        - Nom     :  Brice KENGNI ZANGUIM\n",
    "        - E-mail  :  kenzabri2@yahoo.com\n",
    "    \"\"\"\n",
    "    ####################################################################\n",
    "    ####     Transformation des entrées en un tenseur d'ordre 1    #####\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    \n",
    "    #if tf.math.all( y_true_f == y_pred_f ) :\n",
    "    #    return 1.\n",
    "    \n",
    "    nij = tf.math.confusion_matrix(y_true_f,y_pred_f) \n",
    "    \n",
    "    a_i = tf.reduce_sum(nij, axis=0)\n",
    "    b_j = tf.reduce_sum(nij, axis=1)\n",
    "    \n",
    "    a_i_sum = tf.reduce_sum(a_i * (a_i - 1), axis=0)\n",
    "    b_i_sum = tf.reduce_sum(b_j * (b_j - 1), axis=0)\n",
    "    n = tf.size(y_pred_f)\n",
    "\n",
    "    RI = tf.reduce_sum(nij * (nij - 1), axis=(0,1) )\n",
    "    max_RI = ( a_i_sum + b_i_sum ) / 2\n",
    "    expected_RI = a_i_sum * b_i_sum / n\n",
    "    \n",
    "    RI = tf.cast(RI, tf.float32)\n",
    "    expected_RI = tf.cast(expected_RI, tf.float32)\n",
    "    max_RI = tf.cast(max_RI, tf.float32)\n",
    "    \n",
    "    return (RI - expected_RI) / (max_RI - expected_RI)\n",
    "\n",
    "def ARI_loss( y_true ,y_pred ) :\n",
    "    \n",
    "    return 1 - ARI_score(y_true, y_pred)\n",
    "\n",
    "##############################################################################\n",
    "##################           Entropie mixte            #######################\n",
    "##############################################################################\n",
    "\n",
    "def mixt_entropi(y_true =None , y_pred=None, iou_coef=1.4, twersky_coef=1.4,dice_coef=1.2, ari_coef = 0.04) :\n",
    "    \n",
    "    IOU = iou_coef*IoU_loss(y_true, y_pred)\n",
    "    TVERSKY =  twersky_coef*Tversky_loss(y_true, y_pred)\n",
    "    DICE =  dice_coef*dice_loss( y_true,y_pred )\n",
    "    ARI = ari_coef*ARI_loss( y_true, y_pred )\n",
    "    \n",
    "    return categorical_crossentropy(y_true, y_pred) + IOU + TVERSKY + DICE + ARI\n",
    "    #return CategoricalCrossentropy()(y_true, y_pred) + IOU + TVERSKY + DICE + ARI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5ed532-e581-479a-b606-87b8e7f703f7",
   "metadata": {},
   "source": [
    "## <strong> Mes classes personnalisées"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773b73f5-1d64-4116-9ca1-78ac28984a7f",
   "metadata": {},
   "source": [
    "- ### <strong> Transformer de masques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f30c945-9c7d-4ba1-b587-6ab7d1a20b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mask_To_8_Groups(BaseEstimator,TransformerMixin):\n",
    "    \n",
    "    \"\"\"\n",
    "        Description :\n",
    "        ---------------\n",
    "        \n",
    "        Cette classe prends transforme une matrice de taille (n,m) en un tenseur de configuration (n,m,k) où k est le nombre de catégories \n",
    "        suivant la troisième dimension k, les composantes sont des vecteurs qui One hot Encode les pixels présents sur la matrice de départ\n",
    "        \n",
    "        D'une certaine façon celà équivaut à un One hot Encode des différentes valeurs de pixels présents sur la matrice de départ d'où la\n",
    "        troisième dimension k qui a pour valeur le nombre de categories\n",
    "        \n",
    "        Author :\n",
    "        -----------\n",
    "            Name : Brice KENGNI ZANGUIM\n",
    "            e-mail : kenzabri2@yahoo.com\n",
    "    \"\"\"\n",
    "    ########################################################################################################\n",
    "    #############        catégorie de groupage par defaut. L'utilisateur peut  fournir         #############\n",
    "    ############# une autre catergorisation de groupage lors de l'instantiation de la Classe   #############\n",
    "    categorie_par_defaut =  {\n",
    "                    'void': [0, 1, 2, 3, 4, 5, 6],\n",
    "                    'flat': [7, 8, 9, 10],\n",
    "                    'construction': [11, 12, 13, 14, 15, 16],\n",
    "                    'object': [17, 18, 19, 20],\n",
    "                    'nature': [21, 22],\n",
    "                    'sky': [23],\n",
    "                    'human': [24, 25],\n",
    "                    'vehicle': [26, 27, 28, 29, 30, 31, 32, 33, -1]\n",
    "                }\n",
    "    \n",
    "    #############################################################################################################\n",
    "    #############  Palette de couleurs par defaut pour les classes si l'on veut que chaque classe   #############\n",
    "    #############  soit représentée par une couleur bien spécifique en RGB. Les couleurs doivent    #############\n",
    "    #############    suivre le même ordre de definition que dans le dictionnaire de catégories      #############\n",
    "    palette_couleur_par_defaut =[ 'ivory', 'lightgrey', 'plum', 'olive', 'forestgreen', 'skyblue', 'orangered', 'navy']\n",
    "    \n",
    "    def __init__( self, categorie = None, palette_couleur = None):\n",
    "        ############################################################################################################\n",
    "        #############  Si une categorisation est fournie lors de l'instantiation alors je l'utilise    #############\n",
    "        if categorie :\n",
    "            assert isinstance(categorie, dict)\n",
    "            self.categorie = categorie\n",
    "        \n",
    "        ###################################################################################\n",
    "        #############  Sinon j'utilise plutot une categorisation par defaut   #############\n",
    "        else :\n",
    "            self.categorie = Mask_To_8_Groups.categorie_par_defaut\n",
    "        self.nom_des_categories = self.categorie.keys()\n",
    "        self.numero_des_categories = np.array(range(len(self.categorie)) )\n",
    "        if np.all(palette_couleur) :\n",
    "            self.palette_couleur = palette_couleur\n",
    "            assert len(self.palette_couleur) == len(self.categorie)\n",
    "        else :\n",
    "            self.palette_couleur = Mask_To_8_Groups.palette_couleur_par_defaut\n",
    "        \n",
    "\n",
    "    def fit( self, categorie, palette_couleur = None ):\n",
    "        self.categorie = categorie\n",
    "        self.nom_des_categories = categorie.keys()\n",
    "        self.numero_des_categories = np.array(range(len(self.categorie)) )\n",
    "        \n",
    "        if np.all( palette_couleur ) :\n",
    "            self.palette_couleur = palette_couleur\n",
    "            assert len(self.palette_couleur) == len(self.categorie)\n",
    "\n",
    "    \n",
    "    def transform(self ,img ,y = None ):\n",
    "        img = np.array( img ) \n",
    "        \n",
    "        #############################################################################\n",
    "        ############# Initialisation d'un masque de taille (n ,m ,k )   #############\n",
    "        mask = np.zeros( (img.shape[0], img.shape[1], len( self.nom_des_categories ) ) ) \n",
    "        \n",
    "        ####################################################################################################\n",
    "        ############# je parcours toute la liste des identifiants `Id` des différents objets   #############\n",
    "        for Id in range(-1, 34):\n",
    "            ####################################################################################################\n",
    "            #############     Je parcours toute la liste des noms de catégories d'objets afin de    ############\n",
    "            #############   rechercher la catégorie qui associée à l'Id et créer le canal associé   ############\n",
    "            for pos, cat in enumerate(self.nom_des_categories) :\n",
    "                if Id in self.categorie[cat]:\n",
    "                    #mask[:, :, pos] = np.logical_or(mask[:, :, pos], img == Id )\n",
    "                    mask[:, :, pos][img == Id] = 1\n",
    "                    break\n",
    "\n",
    "        return mask\n",
    "    \n",
    "    def fit_transform ( self ,img ,categorie = None )  :\n",
    "        if categorie :\n",
    "            self.fit( categorie )\n",
    "        \n",
    "        return self.transform(img)\n",
    "    \n",
    "    def invers_transform( self, mask ) :\n",
    "        \"\"\"\n",
    "        Prends le masque en entrée et reconstruit l'image d'origine au format noir sur blanc\n",
    "        La petite nuance est qu'il y a à présents autant de niveaux de pixels que de groupes associés à la transformation\n",
    "        l'image n'est donc pas ramenée au 34 groupes initiaux qui apparaissaient sur l'image originale mais au nombre de \n",
    "        groupes réduis associés à la transformation; soit 8 groupes pas defaut.  Pour remontrer aux 34 groupes de départ \n",
    "        il faurdrait une astuce plus ingénieuse.\n",
    "        \"\"\"\n",
    "        \n",
    "        #img = np.zeros((mask.shape[0], mask.shape[1]))\n",
    "        ###############################################################################################################\n",
    "        ################  Je me crèe un vectoriser qui donne le pouvoir à une fonction de pouvoir          ############ \n",
    "        ################  se transformer en une fonction vectorielle multidimension definie de E vers E    ############ \n",
    "        #f = np.vectorize(lambda x: self.numero_des_categories[x] )\n",
    "        \n",
    "        ############################################################################################################################\n",
    "        ####################  Ma fonction vectorielle prends toutes les indexes où se trouvent les maximum              ############ \n",
    "        ####################  dans la troisième dimension et y retourne la position le numero de categori  équivalent   ############ \n",
    "        if mask.ndim == 3 and mask.shape[-1] == 8 : \n",
    "            return np.argmax(mask, axis=2)    # Ceci tire profit du fait que les numéro de catégories sont ordonnés à partir de 0\n",
    "        \n",
    "        elif mask.ndim == 3 and mask.shape[-1] == 3  :  # Images au format RGB\n",
    "            output_mask = np.zeros(mask.shape[0]* mask.shape[1])\n",
    "            x = mask.reshape((-1,3))\n",
    "            for classe, couleur in enumerate(self.palette_couleur) :\n",
    "                output_mask[ np.prod(x == colors.to_rgb( couleur ), axis = 1, dtype=bool) ] = classe\n",
    "            \n",
    "            return output_mask.reshape((mask.shape[0],mask.shape[1] ))\n",
    "        \n",
    "        #return  f( np.argmax(mask, axis=2)  )\n",
    "        \n",
    "    def fit_transform_to_specific_color_set(self,mask, palette_couleur = None ) :\n",
    "        if palette_couleur : self.palette_couleur = palette_couleur\n",
    "        \n",
    "        ##################################################################################################################\n",
    "        ###############  J'initialise à zéro tous les éléments de l'image RGB qui seras renvoyé en sorti    ##############\n",
    "        img_rgb = np.zeros((mask.shape[0], mask.shape[1], 3), dtype= float)\n",
    "                        \n",
    "        if np.ndim( mask ) == 3 :\n",
    "            ###################################################################################################################\n",
    "            ###########    Avant toute chose on se rassure que la profondeur du masque ( sa troisième dimenssion)     #########\n",
    "            ###########          a la même longueur que le dictionnaires des classes (  nombre de classe )            #########\n",
    "            # assert mask.shape[-1] == len( self.categorie ) # Uniquement que si la fonction invers_transform ne prends pas les images RGB\n",
    "            \n",
    "            ##############################################################################################################\n",
    "            ###########    Je ramène mon masque de 3 dimensions à un masque de 2 dimension (niveau de gris )     #########\n",
    "            mask = self.invers_transform(mask)\n",
    "        \n",
    "        assert np.ndim(mask) == 2\n",
    "        for cats in np.unique(mask) :\n",
    "            for i in [0,1,2] :\n",
    "                img_rgb[:,:,i][ mask == cats ] = colors.to_rgb( self.palette_couleur[cats] )[i]\n",
    "        \n",
    "        return img_rgb\n",
    "        \n",
    "        ###Pour chaque cétégorie, donne la valeur de la couleur du pixel (pour R, G et B)\n",
    "        ###for cat in range(len(self.categorie)):\n",
    "        ###    for i in [0,1,2] :\n",
    "        ###        img_rgb[:, :,i] += mask[:, :, cat] * colors.to_rgb(colors_palette[cat])[i]\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c74a35e-c59e-4755-9209-2db8c62f7c29",
   "metadata": {},
   "source": [
    "- ### <strong> Générateur d'images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a6b4936-e170-4863-8fac-1fab7635606c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyImagesGenerator ( keras.utils.Sequence ):\n",
    "    \n",
    "    default_image_size = (128,256)\n",
    "    \n",
    "    #####################################################################################################################################\n",
    "    #####      Essentiellement utile lorsque les données d'entrainement de teste et de validation sont dans le même dossier        ######\n",
    "    #####  Les variables de classe serviront à faire la séparation entre les données train/test/validation dans un seul dossier    ######\n",
    "    nombre_d_instances = 0\n",
    "    fichiers_libres = []\n",
    "    \n",
    "    def __init__( self, chemin_image, chemin_masque, batch_taille, shuffle =False, taille_des_donnees = None,  augmentation = False, \n",
    "                   aug_batch_size = 2, aug_nb_batch = 2, cats = None, mask_transformer=None, target_size = None): \n",
    "        \"\"\"\n",
    "            La fonction permet d'initialiser les attributs d'instances de l'instance de classe nouvellement déclarée\n",
    "\n",
    "            Paramètres :\n",
    "            ---------------\n",
    "                chemin_image, chemin_masque  : Str \n",
    "                    Chemin d'accès aux images et aux masques associés. Il est important de terminer la définition des chemin par le caractère \"/\"\n",
    "                    Si celà n'est pas respecté le programme effectue une correction automatique sur les chemins concernés.\n",
    "                batch_taille : int \n",
    "                    Taille d'un paquet de données (batch)\n",
    "                shuffle : Boolean\n",
    "                    Grandeur booléenne qui permet de spécifier si on doit modifier l'ordre de rangement des données qui seront transmises au modèle\n",
    "                    de Deep Learning. Les valeurs admises sont \"True\" et \"False\"\n",
    "                target_size : tuple\n",
    "                    Un tuple qui défini les dimensions des images si elles doivent être redimensionnés ou non. Si aucune valeur n'est spécifiée\n",
    "                    alors les images sont utilisées sans être redimensionnées\n",
    "                cats : dict\n",
    "                    dictionnaire des catégories de regroupement des classes si ce dernier. S'il n'est pas foruni alors la classification utilisée\n",
    "                    par defaut est celle en 8 groupes spécifié sur le site https://www.cityscapes-dataset.com/dataset-overview/\n",
    "                    Voire la classe Mask_To_8_Groups() pour plus de détails.\n",
    "                taille_des_donnees : int\n",
    "                    Nombre de couple ( image , masque ) a retenir parmi la liste disponible dans les dossiers indiqués par les chemins\n",
    "                augmentation : Bool\n",
    "                    Précise si une augmentation des données doit être faite ou non\n",
    "                aug_batch_size, aug_nb_batch : int\n",
    "                    respectivement la taille et le nombre de batch à générer dans la classe d'augmentation de données afin de réduire le temps de\n",
    "                    génération des images et masques augmentés\n",
    "                    \n",
    "            return : dict\n",
    "            ---------------\n",
    "                None\n",
    "\n",
    "            Author : \n",
    "            -----------\n",
    "                Name : Brice KENGNI ZANGUIM\n",
    "                e-mail : kenzabri2@yahoo.com\n",
    "        \"\"\"\n",
    "        #######################################################################################\n",
    "        ######################  Incrément du nombre d'instances créés  ########################\n",
    "        MyImagesGenerator.nombre_d_instances += 1\n",
    "        \n",
    "        #########################################################################\n",
    "        ######################  Préparation des données  ########################\n",
    "        if chemin_image[-1] != \"/\" : chemin_image += \"/\"\n",
    "        if chemin_masque[-1] != \"/\" : chemin_masque += \"/\"\n",
    "        \n",
    "        ######################################################################################################\n",
    "        ########################  Il faut vérifier que les masques et les images ne ##########################\n",
    "        ########################       sont pas logés dans le même repertoire     ############################ \n",
    "        assert chemin_image != chemin_masque , \"Veillez spécifier des chemin d'accès différents pour les images et les masques\"\n",
    "        self.chemin_image = chemin_image\n",
    "        self.chemin_masque = chemin_masque\n",
    "        \n",
    "        #####################################################################################################\n",
    "        #############  Les fichier correspondants images et masque doivent avoir le même nom  ###############\n",
    "        #############  On se rassure que les fichiers masques et images on les mêmes noms     ###############\n",
    "        if MyImagesGenerator.nombre_d_instances == 1 : \n",
    "            # On initialise la liste des fichiers libre et on on se rassure que les noms de fichiers sont iddentiques dans les deuc chemins\n",
    "            MyImagesGenerator.fichiers_libres = np.array( [ i for i in os.listdir(self.chemin_image) if \".png\" in i] )\n",
    "            assert sorted(MyImagesGenerator.fichiers_libres) == sorted([ i for i in os.listdir(self.chemin_masque) if \".png\" in i] )\n",
    "\n",
    "        ####################################################################################################\n",
    "        ###############     Definition de la liste de fichier propres à l'instance créée      ##############\n",
    "        assert len(MyImagesGenerator.fichiers_libres) >= taille_des_donnees , \"Le nombre de données demandée est suppérieur au nombre disponible\"\n",
    "        self.files_name = np.random.choice( MyImagesGenerator.fichiers_libres , taille_des_donnees, replace = False )\n",
    "\n",
    "        #######################################################################################################\n",
    "        ###############             Mise à jour de la liste de fichiers disponibles              ##############\n",
    "        MyImagesGenerator.fichiers_libres = np.array( [ files \n",
    "                                                        for files in MyImagesGenerator.fichiers_libres  \n",
    "                                                        if files not in self.files_name  \n",
    "                                                      ] )           \n",
    "            \n",
    "        ########################################################################################\n",
    "        ###############         Definition des indexes d'accès aux données        ##############\n",
    "        self.indexes = np.arange(len(self.files_name))\n",
    "            \n",
    "        \n",
    "        ######################################################\n",
    "        #################      DIVERS      ###################\n",
    "        self.batch_taille = batch_taille\n",
    "        self.shuffle = shuffle\n",
    "        self.augmentation = augmentation\n",
    "        self.aug_batch_size = aug_batch_size\n",
    "        self.aug_nb_batch = aug_nb_batch\n",
    "        \n",
    "        if target_size : \n",
    "            self.target_size = target_size\n",
    "        else :\n",
    "            self.target_size = MyImagesGenerator.default_image_size\n",
    "        \n",
    "        ###############################################################################\n",
    "        ###############   Transformer pour la transformation du masque   ##############\n",
    "        if mask_transformer : \n",
    "            self.mask_transformer = mask_transformer\n",
    "        else :\n",
    "            self.mask_transformer = Mask_To_8_Groups( Mask_To_8_Groups.categorie_par_defaut )\n",
    "        \n",
    "        ################################################################################################\n",
    "        ##############     Je lance un premier appel à la fonction on_epoch_end() pour     #############\n",
    "        ##############    randomiser l'ordre des données, ceci en créant de l'aléatoire    #############\n",
    "        ##############     à l'ordre de primaire de la variable d'instance \"indexes\"       #############\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def __len__(self) :\n",
    "        \"\"\"\n",
    "        Permet de définir le nombre de batch qui seront transmis au modèle durant l'itération. Le calcul se base sur la taille totale \n",
    "        des données et la taille d'un batch.\n",
    "        \n",
    "        En un sens, si j'ai 100 images à passer à mon modèle durant une itération et que la taille du batch est de 3 alors on aura en tout\n",
    "        100//3 batchs ou paquets de 3 items chacun qui seront constitués et envoyés progressivement au modèle \n",
    "        \"\"\"\n",
    "        ###################################################################################################################################\n",
    "        ############## Je retourne le nombre de requête de batch qui doivent être effectués à chaque itération ou epoch  ##################\n",
    "        return int( np.ceil( len(self.files_name)/self.batch_taille ) )\n",
    "        \n",
    "    def __getitem__(self, index) :\n",
    "        \"\"\"\n",
    "        C'est cette fonction qui est appelée chaque fois que necessaire lorsque le modèle a besoin d'un nouveau batch de donnée\n",
    "        Elle est appelée avec un argument \"index\" qui spécifie l'ordre du batch. Par exemple lors du premier appel de la fonction pendant \n",
    "        l'entrainement du modèle, index prends la valeur 0, pour le second batch index prends la valeur 1 et ainsi de suite.\n",
    "        \"\"\"\n",
    "        if index == self.__len__() - 1 : \n",
    "            position_dans_la_liste_de_donnees = self.indexes[ index*self.batch_taille : ]\n",
    "        else :\n",
    "            position_dans_la_liste_de_donnees = self.indexes[ index*self.batch_taille : (index+1)*self.batch_taille ]\n",
    "        \n",
    "        #images, mask = [], []\n",
    "        #for idx in position_dans_la_liste_de_donnees :\n",
    "        #     images.append( np.array( image_utils.load_img( self.chemin_image+ self.files_name[idx] ) ) )\n",
    "        \n",
    "        ###############################################################################################\n",
    "        ############  Je charge les images, ensuite je les transforme en une matrice    ###############\n",
    "        ############  np.array() et pour finir j'ajoute le tout à la liste des images   ###############\n",
    "        images = [  np.array( \n",
    "                              image_utils.load_img( self.chemin_image + name, target_size = self.target_size,\n",
    "                                                   interpolation=\"lanczos\"  ) , dtype= 'uint8'\n",
    "                             )  \n",
    "                      for name in self.files_name[ position_dans_la_liste_de_donnees ] \n",
    "                 ]\n",
    "\n",
    "        ################################################################################################\n",
    "        ############  Je charge les masques, ensuite je les transforme en une matrice    ###############\n",
    "        ############  np.array() et pour finir j'ajoute le tout à la liste des images    ###############            \n",
    "        masks = [   np.array( \n",
    "                              image_utils.load_img(self.chemin_masque + name, grayscale = True,\n",
    "                                                   target_size = self.target_size, interpolation=\"lanczos\" ) , dtype = 'uint8'\n",
    "                             )  \n",
    "                        for name in self.files_name[ position_dans_la_liste_de_donnees ]\n",
    "               ]\n",
    "        \n",
    "        ########################################################\n",
    "        ############  Augmentation des images    ###############\n",
    "        if self.augmentation : \n",
    "            augmenter = AugmentationImagesEtMask( images , masks, batch_size = self.aug_batch_size , nb_batch = self.aug_nb_batch ,  )\n",
    "            images, masks = augmenter.transform()\n",
    "        \n",
    "        #################################################################\n",
    "        ############  encodage des masque en 8 classes    ###############\n",
    "        masks = [  self.mask_transformer.transform( i )   for i in masks ]        \n",
    "        \n",
    "        ##########################################################################################\n",
    "        ########   Je remodifie l'ordre des données du batch et les renvoie au modèle   ##########\n",
    "        x = np.arange(len(images))\n",
    "        np.random.shuffle(x)       # mélangeur\n",
    "        return np.array(images)[x] , np.array(masks)[x]\n",
    "        \n",
    "    def on_epoch_end( self ) :\n",
    "        \"\"\"\n",
    "        Cette fonction est appelée à la fin de chaque itération.\n",
    "        Elle peut entre autre permettre de définir la façon dont les données seront transmises aux modèles. Supposons que lors de l'itération actuelle\n",
    "        les items 1 et 3 faisaient parti d'un même batch, on peut s'arranger pour que lors de l'itération suivante ces deux items soient transmis au \n",
    "        modèle dans deux batch distinct; par exemple l'item 1 étant trans mis via le deuxième batch et l'item 3 est transmis via le dixième batch.\n",
    "        \n",
    "        Cette opération est rendue possible modifiant l'ordre dans lequel les items sont rangés entre deux itération; un peu comme si on mélangéait\n",
    "        des cartes dans un jeux de cartes. Celà permet de réduire les effets du batch sur les résultats de l'entrainement du modèle.\n",
    "        \n",
    "        La fonction trouve surtout son importance lorsqu'il faut\n",
    "        \"\"\"\n",
    "        if self.shuffle  :\n",
    "            np.random.shuffle(self.indexes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35d618e-9a65-4661-9f1e-42499d42b598",
   "metadata": {},
   "source": [
    "- ### <strong> Augmenteur d'images et de masques dans les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbda6f72-ca28-404e-bee6-d1950e9d4168",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AugmentationImagesEtMask (  ) :\n",
    "    \n",
    "    # Sometimes(0.5, ...) applies the given augmenter in 50% of all cases,\n",
    "    # e.g. Sometimes(0.5, GaussianBlur(0.3)) would blur roughly every second\n",
    "    # image.\n",
    "    sometimes = lambda aug: iaa.Sometimes(0.3, aug)\n",
    "\n",
    "    # Define our sequence of augmentation steps that will be applied to every image.\n",
    "    transformation_par_defaut = iaa.Sequential(\n",
    "                                                [   # Apply affine transformations to some of the images\n",
    "                                                    # - scale to 80-120% of image height/width (each axis independently)\n",
    "                                                    # - translate by -10 to +10 relative to height/width (per axis)\n",
    "                                                    # - rotate by -45 to +45 degrees\n",
    "                                                    # - shear by -16 to +16 degrees\n",
    "                                                    # - order: use nearest neighbour or bilinear interpolation (fast)\n",
    "                                                    # - mode: use any available mode to fill newly created pixels\n",
    "                                                    #         see API or scikit-image for which modes are available\n",
    "                                                    # - cval: if the mode is constant, then use a random brightness\n",
    "                                                    #         for the newly created pixels (e.g. sometimes black,\n",
    "                                                    #         sometimes white)\n",
    "                                                    sometimes(iaa.Affine(\n",
    "                                                        scale={\"x\": (0.9, 1.1), \"y\": (0.95, 1.05)},\n",
    "                                                        translate_percent={\"x\": (-0.05, 0.05), \"y\": (-0.05, 0.05)},\n",
    "                                                        rotate=(-7, 7),\n",
    "                                                        shear=(-4, 4),\n",
    "                                                        order=[0, 1],\n",
    "                                                        cval=(0, 255),\n",
    "                                                        mode=imgaug.ALL\n",
    "                                                    )),\n",
    "                                                    \n",
    "                                                   # Execute 0 to 1 of the following (less important) augmenters per\n",
    "                                                    # image. Don't execute all of them, as that would often be way too\n",
    "                                                    # strong.\n",
    "                                                    #\n",
    "                                                    iaa.SomeOf((0, 1),\n",
    "                                                        [   # Blur each image with varying strength using\n",
    "                                                            # gaussian blur (sigma between 2.0 and 5.0),\n",
    "                                                            # average/uniform blur (kernel size between 2x2 and 7x7)\n",
    "                                                            # median blur (kernel size between 3x3 and 11x11).\n",
    "                                                            iaa.RemoveSaturation((0.0, 1.0)),\n",
    "                                                            \n",
    "                                                            # Sharpen each image, overlay the result with the original\n",
    "                                                            # image using an alpha between 0 (no sharpening) and 1\n",
    "                                                            # (full sharpening effect).\n",
    "                                                            iaa.Sharpen(alpha=(0, 1.0), lightness=(1., 1.8)),\n",
    "\n",
    "                                                            # Change brightness of images (70-180% of original value).\n",
    "                                                            iaa.Multiply((.85, 1.8), per_channel=0.5),\n",
    "                                                            \n",
    "                                                            sometimes( iaa.AdditiveGaussianNoise( loc=0, scale=(0.0, 0.007 * 155), per_channel=0.2) ),\n",
    "                                                            \n",
    "                                                            iaa.Snowflakes(flake_size=(0.08, 0.1), speed=(0.01, 0.05)),\n",
    "                                                            \n",
    "                                                            iaa.Clouds() ,\n",
    "                                                            \n",
    "                                                            #sometimes(iaa.FastSnowyLandscape( lightness_threshold=(100, 255), lightness_multiplier=(1.0, 2.0)) ),\n",
    "                                                            # crop some of the images by 0-7% of their height/width\n",
    "                                                            sometimes(iaa.Crop(percent=(0, 0.007))),\n",
    "\n",
    "                                                            iaa.SaltAndPepper(\n",
    "                                                                (0.0, 0.005)\n",
    "                                                            ), \n",
    "                                                             ## add rain\n",
    "                                                            sometimes(  iaa.Rain(drop_size=(0.001), speed=(0, 0.01)) ),\n",
    "                                                            \n",
    "\n",
    "                                                        ],\n",
    "                                                        # do all of the above augmentations in random order\n",
    "                                                        random_order=True\n",
    "                                                    )\n",
    "                                                ],\n",
    "                                                # do all of the above augmentations in random order\n",
    "                                                random_order=True\n",
    "                                            )\n",
    "\n",
    "    def __init__ ( self, image, mask, batch_size=3, nb_batch=4, transformations = None) :\n",
    "        if not isinstance( image,  list) :\n",
    "            self.image = [image]\n",
    "            self.mask = [mask]\n",
    "        else : \n",
    "            self.image = image\n",
    "            self.mask = mask\n",
    "                    \n",
    "        #######################################################################\n",
    "        ########   Utile pour le mode augmentation multiprocesseur    #########\n",
    "        self.batch_size = batch_size\n",
    "        self.nb_batch = nb_batch\n",
    "        \n",
    "        #############################################################################################################\n",
    "        ########   Objet definissant l'ensemble des transformations à appliquer sur l'image et le masque    #########        \n",
    "        if transformations :\n",
    "            self.transformations = transformations\n",
    "        else :\n",
    "            self.transformations = AugmentationImagesEtMask.transformation_par_defaut\n",
    "        \n",
    "        ##############################################################\n",
    "        #######   Sortie des résultats des transformations   #########\n",
    "        # return self.transform()  # Opération strictement interdite dans la fonction __init__()\n",
    "        \n",
    "    def transform(self) :\n",
    "        #################################\n",
    "        imgaug.seed( np.random.randint(1,20) )\n",
    "        \n",
    "        img_finale, mask_final  =[], []\n",
    "        for image, mask in zip( self.image, self.mask ) :\n",
    "            ################################################################################################\n",
    "            ######      Objet masque représentant une association entre une image et son masque      #######\n",
    "            segmap = SegmentationMapsOnImage( mask, shape = image.shape )\n",
    "        \n",
    "            ##############################################################################################################################\n",
    "            ######    Initialisation d'un batch de masques avec des copies de masques en autant de fois quela taille du batch      #######          \n",
    "            segmaps = [segmap for _ in range( self.batch_size ) ]        \n",
    "        \n",
    "            ############################################################################################################################\n",
    "            ######    Initialisation d'un batch d'images avec des copies de l'image en autant de fois quela taille du batch      #######        \n",
    "            images = [ image for _ in range( self.batch_size ) ]\n",
    "        \n",
    "            #######################################################################################################################\n",
    "            ######    Création de notre liste de batchs à partir des deux batch images et masques précédement definies      #######         \n",
    "            batches = [ UnnormalizedBatch(images=images, segmentation_maps=segmaps) for _ in range(self.nb_batch) ]\n",
    "        \n",
    "            ########################################################################################################################\n",
    "            #########        transformation des images - Le paramètre `background` active le mode multiprocess            ########## \n",
    "            batches_aug = list( self.transformations.augment_batches( batches, background = False ) )\n",
    "\n",
    "            img_finale.extend([ batches_aug[j].images_aug[i] for i in range(self.batch_size) for j in range(self.nb_batch) ])\n",
    "        \n",
    "            #################################################\n",
    "            ######    transformation des masques      ####### \n",
    "            mask_final.extend([  batches_aug[j].segmentation_maps_aug[i].get_arr() \n",
    "                              for i in range(self.batch_size) \n",
    "                              for j in range(self.nb_batch)\n",
    "                         ])\n",
    "        \n",
    "            ##############################################################################################################################\n",
    "            ######    rajout des originaux des images et masques en bout de liste des images et masques augmentés/transformés      ####### \n",
    "        \n",
    "            img_finale.append( image )\n",
    "            mask_final.append( mask )\n",
    "        \n",
    "        return img_finale, mask_final"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
